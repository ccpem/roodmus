{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting functions of figure 4 in the manuscript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mrcfile\n",
    "\n",
    "from emmer.pdb.convert.convert_pdb_to_map import convert_pdb_to_map\n",
    "from emmer.ndimage.filter.low_pass_filter import low_pass_filter\n",
    "from emmer.ndimage.filter.smoothen_mask import smoothen_mask\n",
    "\n",
    "# roodmus\n",
    "from roodmus.analysis.utils import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_precision_per_class(df_truth, df_picked, classification_job):\n",
    "    result = {\n",
    "        \"class\": [],\n",
    "        \"precision\": [],\n",
    "        \"number_of_particles\": [],\n",
    "        \"picked_fraction\": [],\n",
    "        \"fraction_of_true_positives\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "    num_gt_particles = len(df_truth)\n",
    "    df_picked_grouped = df_picked.groupby(\"jobtype\").get_group(classification_job).groupby(\"class2D\")\n",
    "    num_gt_particles_in_picked = len(df_picked.groupby(\"jobtype\").get_group(classification_job).query(\"TP == True\"))\n",
    "    print(f\"number of particles in ground truth: {num_gt_particles}\")\n",
    "    print(f\"number of particles in picked: {num_gt_particles_in_picked}\")\n",
    "    num_picked_particles = len(df_picked.groupby(\"jobtype\").get_group(classification_job))\n",
    "    for class2d in df_picked_grouped.groups:\n",
    "        particles_in_class = len(df_picked_grouped.get_group(class2d))\n",
    "        print(f\"number of picked particles in class {class2d}: {particles_in_class}. Fraction of picked particles: {np.round(particles_in_class / num_picked_particles, 2)}\")\n",
    "        TP_in_class = len(df_picked_grouped.get_group(class2d).query(\"TP == True\"))\n",
    "        precision_in_class = TP_in_class / particles_in_class\n",
    "        print(f\"precision in class {class2d}: {np.round(precision_in_class, 2)}\")\n",
    "        print(f\"TP fraction in class: {np.round(TP_in_class / num_gt_particles_in_picked, 2)}\")\n",
    "        print(f\"test: {np.round((TP_in_class/num_gt_particles_in_picked) / (particles_in_class/num_picked_particles), 2)}\")\n",
    "\n",
    "        result[\"class\"].append(int(class2d))\n",
    "        result[\"precision\"].append(precision_in_class)\n",
    "        result[\"number_of_particles\"].append(particles_in_class)\n",
    "        result[\"picked_fraction\"].append(particles_in_class / num_picked_particles)\n",
    "        result[\"fraction_of_true_positives\"].append(TP_in_class / num_gt_particles_in_picked)\n",
    "\n",
    "    df_result = pd.DataFrame(result)\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data loading\n",
    "# project_dir = \"/home/mjoosten1/projects/roodmus/data/DE-Shaw_covid_spike_protein/DESRES-Trajectory_sarscov2-11021566-11021571-mixed\"\n",
    "project_dir = \"/tudelft/mjoosten1/staff-umbrella/ajlab/MJ/projects/Roodmus/data/DE-Shaw_covid_spike_protein/DESRES-Trajectory_sarscov2-11021566-11021571-mixed\"\n",
    "config_dir = os.path.join(project_dir, \"Micrographs\")\n",
    "meta_files = [\n",
    "    # os.path.join(project_dir, \"Extract\", \"job004\", \"particles.star\"),\n",
    "    # os.path.join(project_dir, \"Extract\", \"job009\", \"particles.star\"),\n",
    "    # os.path.join(project_dir, \"Select\", \"job012\", \"particles.star\"),\n",
    "    os.path.join(project_dir, \"Class3D\", \"job014\", \"run_it025_data.star\"),\n",
    "    os.path.join(project_dir, \"Class3D\", \"job037\", \"run_it025_data.star\"),\n",
    "    os.path.join(project_dir, \"Class3D\", \"job038\", \"run_it025_data.star\"),\n",
    "]\n",
    "\n",
    "jobtypes = {\n",
    "    os.path.join(project_dir, \"Extract\", \"job004\", \"particles.star\"): \"LoG\",\n",
    "    os.path.join(project_dir, \"Extract\", \"job009\", \"particles.star\"): \"topaz\",\n",
    "    os.path.join(project_dir, \"Select\", \"job012\", \"particles.star\"): \"class selection\",\n",
    "    os.path.join(project_dir, \"Class3D\", \"job014\", \"run_it025_data.star\"): \"3_classes\",\n",
    "    os.path.join(project_dir, \"Class3D\", \"job037\", \"run_it025_data.star\"): \"2_classes\",\n",
    "    os.path.join(project_dir, \"Class3D\", \"job038\", \"run_it025_data.star\"): \"10_classes\",\n",
    "}\n",
    "\n",
    "particle_diameter = 100 # approximate particle diameter in Angstroms\n",
    "ugraph_shape = (4000, 4000) # shape of the micrograph in pixels. Only needs to be given if the metadata file is a .star file\n",
    "verbose = True # prints out progress statements\n",
    "ignore_missing_files = True # if .mrc files are missing, the analysis will still be performed\n",
    "enable_tqdm = True # enables tqdm progress bars\n",
    "\n",
    "for i, meta_file in enumerate(meta_files):\n",
    "    if i == 0:\n",
    "        analysis = load_data(meta_file, config_dir, particle_diameter, ugraph_shape=ugraph_shape, verbose=verbose, enable_tqdm=enable_tqdm, ignore_missing_files=ignore_missing_files) # creates the class\n",
    "    else:\n",
    "        analysis.add_data(meta_file, config_dir, verbose=verbose) # updates the class with the next metadata file\n",
    "\n",
    "df_picked = pd.DataFrame(analysis.results_picking)\n",
    "df_truth = pd.DataFrame(analysis.results_truth)\n",
    "# df_precision, df_picked = analysis.compute_precision(df_picked, df_truth, verbose=verbose)\n",
    "df_picked[\"jobtype\"] = df_picked[\"metadata_filename\"].map(jobtypes)\n",
    "df_picked_grouped = df_picked.groupby(\"jobtype\")\n",
    "for group in df_picked_grouped.groups:\n",
    "    print(f\"jobtype: {group}, number of particles: {len(df_picked_grouped.get_group(group))}\")\n",
    "\n",
    "p_match, _, p_unmatched, t_unmatched, closest_truth_index = analysis._match_particles(\n",
    "    meta_files,\n",
    "    df_picked,\n",
    "    df_truth,\n",
    "    verbose=False,\n",
    "    enable_tqdm=True,\n",
    ")\n",
    "df_precision = analysis.compute_1to1_match_precision(\n",
    "    p_match,\n",
    "    p_unmatched,\n",
    "    t_unmatched,\n",
    "    df_truth,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "df_precision[\"jobtype\"] = df_precision[\"metadata_filename\"].map(jobtypes)\n",
    "df_truth[\"pdb_index\"] = df_truth[\"pdb_filename\"].apply(lambda x: int(x.strip(\".pdb\").split(\"_\")[-1]))\n",
    "df_picked[\"closest_truth_index\"] = closest_truth_index\n",
    "df_picked[\"TP\"] = df_picked[\"closest_truth_index\"].apply(lambda x: np.isnan(x) == False)\n",
    "df_picked[\"closest_pdb_index\"] = df_picked[\"closest_truth_index\"].apply(lambda x: df_truth.loc[x, \"pdb_index\"] if np.isnan(x) == False else np.nan)\n",
    "df_precision.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## panel A\n",
    "distributions of the particles in each class over the MD trajectories of the open and closed states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the df_picked data frame that indicates if the particles originates from the open or closed state of the spike protein\n",
    "for classification_job in [\"2_classes\", \"3_classes\", \"10_classes\"]:\n",
    "    df_truth[\"pdb_index\"] = df_truth[\"pdb_filename\"].apply(lambda x: int(x.strip(\".pdb\").split(\"_\")[-1]))\n",
    "    df_picked_grouped = df_picked.query(\"TP == True\").groupby(\"jobtype\").get_group(classification_job)\n",
    "\n",
    "    # if the closest_pdb_index < 8334, the particle originates from the closed state, otherwise it originates from the open state\n",
    "    df_picked_grouped[\"state\"] = df_picked_grouped[\"closest_pdb_index\"] <= 8334\n",
    "    df_picked_grouped[\"state\"] = df_picked_grouped[\"state\"].map({True: \"closed\", False: \"open\"})\n",
    "\n",
    "    # df_picked_grouped[\"class2D\"] = df_picked_grouped[\"class2D\"].astype(int)\n",
    "    df_picked_grouped.sort_values(by=\"class2D\", inplace=True)\n",
    "    num_classes = len(df_picked_grouped.groupby(\"class2D\").groups)\n",
    "    print(f\"found {num_classes} classes\")\n",
    "    colors = sns.color_palette(\"RdYlBu\", n_colors=num_classes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 3.5))\n",
    "    # make kde plot out of the data\n",
    "    kde_picked = sns.kdeplot(\n",
    "        data=df_picked_grouped,\n",
    "        x=\"closest_pdb_index\",\n",
    "        ax=ax,\n",
    "        hue=\"class2D\",\n",
    "        fill=False,\n",
    "        label=\"class2D\",\n",
    "        linewidth=5,\n",
    "        alpha=1,\n",
    "        palette=colors,\n",
    "        legend=True,\n",
    "    )\n",
    "    # add an extra black line over the second class\n",
    "    kde_extra = sns.kdeplot(\n",
    "        data=df_picked_grouped,\n",
    "        x=\"closest_pdb_index\",\n",
    "        ax=ax,\n",
    "        hue=\"class2D\",\n",
    "        palette={r+1:\"black\" for r in range(num_classes)},\n",
    "        label=\"picked_particles\",\n",
    "        linewidth=1,\n",
    "        alpha=1,\n",
    "        fill=False,\n",
    "        legend=False,\n",
    "    )\n",
    "    # add kdeplot of the True particles\n",
    "    ax_truth = ax.twinx()\n",
    "    kde_truth = sns.kdeplot(\n",
    "        data=df_truth,\n",
    "        x=\"pdb_index\",\n",
    "        ax=ax_truth,\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"GT\",\n",
    "        linewidth=2,\n",
    "        fill=False,\n",
    "        alpha=1,\n",
    "        legend=True,\n",
    "    )\n",
    "\n",
    "    # get the legend handles from kde_picked\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    h = [handles[r] for r in range(len(handles)) if labels[r] == \"class2D\"]\n",
    "    h = h[::-1]\n",
    "    h.extend([handles[r] for r in range(len(handles)) if labels[r] == \"GT\"])\n",
    "    l = [f\"class {r+1}\" for r in range(num_classes)] + [\"GT\"]\n",
    "    # add the legend\n",
    "    ax.legend(\n",
    "        handles=h,\n",
    "        labels=l,\n",
    "        loc='upper right',\n",
    "        bbox_to_anchor=(1.40, 1.0),\n",
    "        ncol=1,\n",
    "        fontsize=14,\n",
    "        frameon=True,\n",
    "    )\n",
    "    ax_truth.set_ylabel(\"GT\", fontsize=16, rotation=270, labelpad=20)\n",
    "    if num_classes == 10:\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.set_ylim(ylim[0], ylim[1]*1.1)\n",
    "    else:\n",
    "        ylim = ax_truth.get_ylim()\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    "\n",
    "    # change the xticks to the time in us\n",
    "    ax.set_xticks([0, 8334-1000, 8334+1000, 16668])\n",
    "    ax.set_xticklabels([\"0 \\u03BCs\", \"10 \\u03BCs\", \"0 \\u03BCs\", \"10 \\u03BCs\"], fontsize=14)\n",
    "    ax.axvline(x=8334, color=\"red\", linestyle=\"-.\", linewidth=2)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Density\", fontsize=16)\n",
    "    # label the right side of the plot with 'open state' and the left side with 'closed state' undeneath the x-axis\n",
    "    ax.text(0.25, -0.2, \"Closed state\", ha='center', va='bottom', fontsize=16, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.text(0.75, -0.2, \"Open state\", ha='center', va='bottom', fontsize=16, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax_truth.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    outfilename = os.path.join(project_dir, \"figures\", f\"frame_distribution_{classification_job}.pdf\")\n",
    "    # fig.savefig(outfilename, bbox_inches=\"tight\")\n",
    "    print(f\"saved figure to: {outfilename}\")\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the 10-class case plot all distributions separately\n",
    "df_picked_grouped = df_picked.query(\"TP == True\").groupby(\"jobtype\").get_group(\"10_classes\")\n",
    "df_picked_grouped[\"state\"] = df_picked_grouped[\"closest_pdb_index\"] <= 8334\n",
    "df_picked_grouped[\"state\"] = df_picked_grouped[\"state\"].map({True: \"closed\", False: \"open\"})\n",
    "df_picked_grouped.sort_values(by=\"class2D\", inplace=True)\n",
    "num_classes = len(df_picked_grouped.groupby(\"class2D\").groups)\n",
    "print(f\"found {num_classes} classes\")\n",
    "colors = sns.color_palette(\"RdYlBu\", n_colors=num_classes)\n",
    "\n",
    "for class2d in df_picked_grouped.groupby(\"class2D\").groups:\n",
    "    fig, ax = plt.subplots(figsize=(7, 3.5))\n",
    "    # make kde plot out of the data\n",
    "    kde_picked = sns.kdeplot(\n",
    "        data=df_picked_grouped.groupby(\"class2D\").get_group(class2d),\n",
    "        x=\"closest_pdb_index\",\n",
    "        ax=ax,\n",
    "        fill=False,\n",
    "        label=\"class2D\",\n",
    "        linewidth=5,\n",
    "        alpha=1,\n",
    "        legend=True,\n",
    "    )\n",
    "    # get the legend handles from kde_picked\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    h = [handles[r] for r in range(len(handles)) if labels[r] == \"state\"]\n",
    "    h = h[::-1]\n",
    "    h.extend([handles[r] for r in range(len(handles)) if labels[r] == \"GT\"])\n",
    "    l = [\"closed\", \"open\", \"GT\"]\n",
    "    # add the legend\n",
    "    ax.legend(\n",
    "        handles=h,\n",
    "        labels=l,\n",
    "        loc='upper right',\n",
    "        bbox_to_anchor=(1.40, 1.0),\n",
    "        ncol=1,\n",
    "        fontsize=14,\n",
    "        frameon=True,\n",
    "    )\n",
    "    ax_truth.set_ylabel(\"GT\", fontsize=16, rotation=270, labelpad=20)\n",
    "    if num_classes == 10:\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.set_ylim(ylim[0], ylim[1]*1.1)\n",
    "    else:\n",
    "        ylim = ax_truth.get_ylim()\n",
    "\n",
    "    # change the xticks to the time in us\n",
    "    ax.set_xticks([0, 8334-1000, 8334+1000, 16668])\n",
    "    ax.set_xticklabels([\"0 \\u03BCs\", \"10 \\u03BCs\", \"0 \\u03BCs\", \"10 \\u03BCs\"], fontsize=14)\n",
    "    ax.axvline(x=8334, color=\"red\", linestyle=\"-.\", linewidth=2)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Density\", fontsize=16)\n",
    "    # label the right side of the plot with 'open state' and the left side with 'closed state' undeneath the x-axis\n",
    "    ax.text(0.25, -0.2, \"closed state\", ha='center', va='bottom', fontsize=16, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.text(0.75, -0.2, \"open state\", ha='center', va='bottom', fontsize=16, fontweight='bold', transform=ax.transAxes)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax_truth.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax.set_title(f\"class {class2d}\")\n",
    "\n",
    "    outfilename = os.path.join(project_dir, \"figures\", f\"frame_distribution_{classification_job}_class{class2d}.png\")\n",
    "    # fig.savefig(outfilename, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"saved figure to: {outfilename}\")\n",
    "\n",
    "    # close the plot\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each class print if there are more particles from the open or closed state\n",
    "df_picked[\"state\"] = df_picked[\"closest_pdb_index\"] <= 8334\n",
    "df_picked[\"state\"] = df_picked[\"state\"].map({True: \"closed\", False: \"open\"})\n",
    "df_picked[\"class2D\"] = df_picked[\"class2D\"].astype(int)\n",
    "\n",
    "for classification_job in [\"2_classes\", \"3_classes\", \"10_classes\"]:\n",
    "    print(f\"jobtype: {classification_job}\")\n",
    "    df_picked_grouped = df_picked.groupby([\"jobtype\", \"TP\"]).get_group((classification_job,True))\n",
    "    # df_picked_grouped[\"state\"] = df_picked_grouped[\"closest_pdb_index\"] <= 8334\n",
    "    # df_picked_grouped[\"state\"] = df_picked_grouped[\"state\"].map({True: \"closed\", False: \"open\"})\n",
    "    # df_picked_grouped[\"class2D\"] = df_picked_grouped[\"class2D\"].astype(int)\n",
    "    # df_picked_grouped.sort_values(by=\"class2D\", inplace=True)\n",
    "    num_classes = len(df_picked_grouped.groupby(\"class2D\").groups)\n",
    "\n",
    "    for class2D in range(1, num_classes+1):\n",
    "        df_class = df_picked_grouped.groupby(\"class2D\").get_group(class2D)\n",
    "        num_open = len(df_class.query(\"state == 'open'\"))\n",
    "        num_closed = len(df_class.query(\"state == 'closed'\"))\n",
    "        percentage_open = num_open / (num_open + num_closed)*100\n",
    "        print(f\"class {class2D}: {num_open} ({percentage_open:.1f}%) open, {num_closed} ({100-percentage_open:.1f}%) closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## panel B\n",
    "plotting the precision of each 3D class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the preicison per 3D class\n",
    "for classification_job in [\"2_classes\", \"3_classes\", \"10_classes\"]:\n",
    "    df_result = get_precision_per_class(df_truth, df_picked, classification_job)\n",
    "    # setup colors\n",
    "    num_classes = len(df_result[\"class\"].unique())\n",
    "    colors = sns.color_palette(\"RdYlBu\", n_colors=num_classes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "    sns.barplot(\n",
    "        data=df_result,\n",
    "        x=\"class\",\n",
    "        y=\"precision\",\n",
    "        hue=\"class\",\n",
    "        palette=colors,\n",
    "        edgecolor='black',\n",
    "        ax=ax,\n",
    "        dodge=0,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    # remove legend\n",
    "    ax.legend().remove()\n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_ylabel(\"Precision\", fontsize=16)\n",
    "    ax.set_xlabel(\"Class\", fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    outfilename = os.path.join(project_dir, \"figures\", f\"precision_{classification_job}.pdf\")\n",
    "    # fig.savefig(outfilename, bbox_inches=\"tight\")\n",
    "    print(f\"saved figure to: {outfilename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## panel C\n",
    "plotting the fraction of particles in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classification_job in [\"2_classes\", \"3_classes\", \"10_classes\"]:\n",
    "    df_result = get_precision_per_class(df_truth, df_picked, classification_job)\n",
    "    # setup colors\n",
    "    num_classes = len(df_result[\"class\"].unique())\n",
    "    colors = sns.color_palette(\"RdYlBu\", n_colors=num_classes)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "    sns.barplot(\n",
    "        data=df_result,\n",
    "        x=\"class\",\n",
    "        y=\"picked_fraction\",\n",
    "        hue=\"class\",\n",
    "        palette=colors,\n",
    "        edgecolor='black',\n",
    "        ax=ax,\n",
    "        dodge=0,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    # remove legend\n",
    "    ax.legend().remove()\n",
    "    ax.set_ylabel(\"particle fraction\")\n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_ylabel(\"Picked fraction\", fontsize=16)\n",
    "    ax.set_xlabel(\"Class\", fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    outfilename = os.path.join(project_dir, \"figures\", f\"picked_fraction_{classification_job}.pdf\")\n",
    "    # fig.savefig(outfilename, bbox_inches=\"tight\")\n",
    "    print(f\"saved figure to: {outfilename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## panel D\n",
    "plotting the correlation matrix between each class and a sampling of the frames in the MD trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/tudelft/mjoosten1/staff-umbrella/ajlab/MJ/projects/Roodmus/data/DE-Shaw_covid_spike_protein/DESRES-Trajectory_sarscov2-11021566-11021571-mixed\"\n",
    "for classification_job in [\"2_classes\", \"3_classes\", \"10_classes\"]:\n",
    "    print(f\"loading data for {classification_job}\")\n",
    "    correlation_matrix_filename = os.path.join(project_dir, \"aligned_ensembles\", f\"correlation_matrix_{classification_job}.npy\")\n",
    "    if os.path.exists(correlation_matrix_filename):\n",
    "        correlation_matrix = np.load(correlation_matrix_filename)\n",
    "    else:\n",
    "        print(f\"correlation matrix for {classification_job} does not exist yet. Compute it first.\")\n",
    "    correlation_matrix_normalised = (correlation_matrix - correlation_matrix.min(axis=0)) / (correlation_matrix.max(axis=0) - correlation_matrix.min(axis=0))\n",
    "    n_classes = correlation_matrix.shape[1]\n",
    "    n_frames = correlation_matrix.shape[0]\n",
    "    print(f\"number of classes: {n_classes}\")\n",
    "    print(f\"number of frames: {n_frames}\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "    # show the heatmap as a square (~50x3)\n",
    "    ax.imshow(correlation_matrix_normalised, cmap=\"coolwarm\", aspect=\"auto\", origin=\"lower\")\n",
    "    ticklabels = [f\"class {i+1}\" for i in range(n_classes)]\n",
    "    ax.set_xticks(range(n_classes))\n",
    "    ax.set_xticklabels(ticklabels, fontsize=12, rotation=45)\n",
    "    ax.set_yticks([0, n_frames//2-2, n_frames//2+2, n_frames-1])\n",
    "    ax.set_yticklabels([\"0 \\u03BCs\", \"10 \\u03BCs\", \"0 \\u03BCs\", \"10 \\u03BCs\"], fontsize=12)\n",
    "    ax.axhline(y=n_frames//2, color=\"black\", linestyle=\"solid\", linewidth=2)\n",
    "    # add colorbar\n",
    "    cbar = ax.figure.colorbar(ax.get_images()[0], ax=ax, orientation=\"vertical\")\n",
    "    ax.text(\n",
    "        -0.65,\n",
    "        3*n_frames//4,\n",
    "        \"Closed state\",\n",
    "        ha='right',\n",
    "        va='bottom',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "    ax.text(\n",
    "        -0.65,\n",
    "        n_frames//4,\n",
    "        \"Open state\",\n",
    "        ha='right',\n",
    "        va='bottom',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "\n",
    "    # save the figure\n",
    "    outfilename = os.path.join(project_dir, \"figures\", f\"correlation_matrix_{n_classes}classes.pdf\")\n",
    "    # fig.savefig(outfilename, bbox_inches=\"tight\")\n",
    "    print(f\"saved figure to: {outfilename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the average correlation with the open and closed states for each class\n",
    "for classification_job in [\"2_classes\", \"3_classes\", \"10_classes\"]:\n",
    "    print(f\"loading data for {classification_job}\")\n",
    "    correlation_matrix_filename = os.path.join(project_dir, \"aligned_ensembles\", f\"correlation_matrix_{classification_job}.npy\")\n",
    "    if os.path.exists(correlation_matrix_filename):\n",
    "        correlation_matrix = np.load(correlation_matrix_filename)\n",
    "    else:\n",
    "        print(f\"correlation matrix for {classification_job} does not exist yet. Compute it first.\")\n",
    "    n_classes = correlation_matrix.shape[1]\n",
    "    n_frames = correlation_matrix.shape[0]\n",
    "    print(f\"number of classes: {n_classes}\")\n",
    "    print(f\"number of frames: {n_frames}\")\n",
    "\n",
    "    # compute the average correlation with the open and closed states for each class\n",
    "    avg_correlation_open = np.zeros(n_classes)\n",
    "    avg_correlation_closed = np.zeros(n_classes)\n",
    "    for i in range(n_classes):\n",
    "        avg_correlation_open[i] = np.mean(correlation_matrix[:n_frames//2, i])\n",
    "        avg_correlation_closed[i] = np.mean(correlation_matrix[n_frames//2:, i])\n",
    "\n",
    "    # plot the average correlation with the open and closed states for each class\n",
    "    fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "    ax.plot(range(1, n_classes+1), avg_correlation_open, label=\"open state\", color=\"blue\")\n",
    "    ax.plot(range(1, n_classes+1), avg_correlation_closed, label=\"closed state\", color=\"red\")\n",
    "    ax.set_xlabel(\"class\", fontsize=16)\n",
    "    ax.set_ylabel(\"average correlation\", fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    outfilename = os.path.join(project_dir, \"figures\", f\"average_correlation_{classification_job}.pdf\")\n",
    "    fig.savefig(outfilename, bbox_inches=\"tight\")\n",
    "    print(f\"saved figure to: {outfilename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in text\n",
    "to report the resolution in text of the refined maps for the 3class dataset I need to load the generated confidence masks and filter them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_dir = \"/home/mjoosten1/projects/roodmus/data/DE-Shaw_covid_spike_protein/DESRES-Trajectory_sarscov2-11021566-11021571-mixed\"\n",
    "# project_dir = \"/tudelft/mjoosten1/staff-umbrella/ajlab/MJ/projects/Roodmus/data/DE-Shaw_covid_spike_protein/DESRES-Trajectory_sarscov2-11021566-11021571-mixed\"\n",
    "# data = {\n",
    "#     0:{\n",
    "#         \"class\": 1,\n",
    "#         \"ConfidenceMap\": \"job103\",\n",
    "#     },\n",
    "#     1: {\n",
    "#         \"class\": 2,\n",
    "#         \"ConfidenceMap\": \"job104\",\n",
    "#     },\n",
    "#     2: {\n",
    "#         \"class\": 3,\n",
    "#         \"ConfidenceMap\": \"job105\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# for key, item in data.items():\n",
    "#     confidence_map_file = os.path.join(project_dir, \"ConfidenceMap\", item[\"ConfidenceMap\"], \"run_class001_confidenceMap.mrc\")\n",
    "#     confidence_map = mrcfile.open(confidence_map_file)\n",
    "#     confidence_mask = confidence_map.data > 0.99\n",
    "\n",
    "#     confidence_mask_smooth = smoothen_mask(\n",
    "#         confidence_mask,\n",
    "#         cosine_falloff_length=5,\n",
    "#     )\n",
    "\n",
    "#     with mrcfile.new(os.path.join(project_dir, \"ConfidenceMap\", item[\"ConfidenceMap\"], \"run_class001_confidenceMap_filtered.mrc\"), overwrite=True) as mrc:\n",
    "#         mrc.set_data(confidence_mask_smooth.astype(np.float32))\n",
    "#         mrc.voxel_size = confidence_map.voxel_size\n",
    "#         mrc.header.origin.x = confidence_map.header.origin.x\n",
    "#         mrc.header.origin.y = confidence_map.header.origin.y\n",
    "#         mrc.header.origin.z = confidence_map.header.origin.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roodmus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
